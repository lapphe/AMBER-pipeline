{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87c5a73d",
   "metadata": {},
   "source": [
    "# AMBER pose estimation steps\n",
    "\n",
    "This notebook walks you through the pose estimation steps of the AMBER pipeline. \n",
    "\n",
    "The steps for pose estiamtion are:\n",
    "1. Pose estimation for dams for all videos\n",
    "2. Create videos to check dam tracking\n",
    "3. Pose estimation for pups for all videos\n",
    "4. Create videos to check pup detections\n",
    "5. \"Unpickle\" pup detection files to convert to csv\n",
    "6. Join and reformat pup and dam pose estimation output so it is ready to use with SimBA\n",
    "\n",
    "These steps will be performed for all of the videos in the directory you specify. The provided code will use the example_videos folder in the AMBER-pipeline directory. \n",
    "\n",
    "_Be sure to run this in your DeepLabCut conda environment_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4839c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required packages and modules\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import deeplabcut\n",
    "import pheno_pickle_raw as PhenoPickleRaw\n",
    "import join_dam_pup\n",
    "import pandas as pd\n",
    "print(\"Finished importing packages and modules\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4961f13",
   "metadata": {},
   "source": [
    "Specify the full path to the dam and pup pose estimation config.yaml files. \n",
    "\n",
    "The config.yaml can be found in AMBER-pipeline/dam-single-animal-Hannah-2022-05-26 and AMBER-pipeline/pup-nine-pt-Hannah-2022-06-05 directories, but you should update the beginning of the path with the location of the AMBER-pipeline folder on your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad3e74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dam_config = './dam-single-animal-Hannah-2022-05-26/config.yaml'\n",
    "pup_config = './pup-nine-pt-Hannah-2022-06-05/config.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9b1ba5",
   "metadata": {},
   "source": [
    "Specify the path to your directory containing the videos to be analyzed and the type of videos using the video extension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c3e571",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_directory = './tutorial_videos'\n",
    "vid_type = '.mp4'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46ecc3c",
   "metadata": {},
   "source": [
    "## Dam pose estimation\n",
    "\n",
    "First, run dam pose estimation on all of the videos in the directory. If you have a lot of videos or your videos are long, this could take a long time.\n",
    "For more information on the deeplabcut.analyze_videos function, see the [DLC documentation](https://deeplabcut.github.io/DeepLabCut/docs/standardDeepLabCut_UserGuide.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55039a5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deeplabcut.analyze_videos(dam_config, [video_directory], save_as_csv = True, videotype=vid_type)\n",
    "print(\"Dam pose estimation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38186a97",
   "metadata": {},
   "source": [
    "### Create dam pose estimation videos\n",
    "\n",
    "It's important to check that the pose estimation models are performing well with your videos. One way to check this is to create a labeled video. Once the videos are created, they are moved to a new subdirectory called \"pose_estimation_videos\" so the labeled videos are not used for pup pose estimation in the next steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee4e8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.create_labeled_video(dam_config, [video_directory], save_frames=False)\n",
    "track_video = video_directory + os.sep + 'pose_estimation_videos' + os.sep\n",
    "  \n",
    "try:\n",
    "    os.makedirs(track_video)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "for file_name in os.listdir(video_directory):\n",
    "    if \"dam-single-animal\" in file_name and file_name.endswith('.mp4'):\n",
    "        src_path = os.path.join(video_directory, file_name)\n",
    "        dst_path = os.path.join(track_video, file_name)\n",
    "        shutil.move(src_path, dst_path)\n",
    "print(\"Completed video creation for dam labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de2a398",
   "metadata": {},
   "source": [
    "## Pup pose estimation\n",
    "\n",
    "Now run pup pose estimation on the videos. The auto_track argument is set to false to only run the detection portion of the multi-animal workflow. This avoids the loss in pup key point detections during individual assembly (when key points are assigned to indidvudal pups during the second part of the DLC multi-animal workflow). See the [DLC docs](https://deeplabcut.github.io/DeepLabCut/docs/maDLC_UserGuide.html) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef4f0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.analyze_videos(pup_config, [video_directory], auto_track=False)\n",
    "print(\"Finished pup pose estimation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb12f86",
   "metadata": {},
   "source": [
    "### Create pup detections videos\n",
    "\n",
    "After labeled videos with pup detections are created, they are also moved to the \"pose_estimation_videos\" folder. Check the videos after they are created to make sure the tracking looks good.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ead3c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.create_video_with_all_detections(pup_config, [video_directory])\n",
    "\n",
    "for file_name in os.listdir(video_directory):\n",
    "    if \"pup-nine-pt\" in file_name and file_name.endswith('.mp4'):\n",
    "        src_path = os.path.join(video_directory, file_name)\n",
    "        dst_path = os.path.join(track_video, file_name)\n",
    "        shutil.move(src_path, dst_path)\n",
    "\n",
    "print(\"Finished creating pup labeled videos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36628e4",
   "metadata": {},
   "source": [
    "### Convert pup detection file from .pickle to .csv\n",
    "\n",
    "The code below will use the pheno_pickle_raw.py script to convert the .pickle files created in the step above that contain the pup detections to csv files. \n",
    "\n",
    "Note: Although detected points are placed in columns contianing pup IDs, this placement is arbitrary and does not necessarily mean that the detected point belongs to that particular pup. For exmaple, the nose, eye, head, and back points assigned to 'pup1' may belong to the same individual pup or may belong to different pups. Likewise, key point assignments to individual pups are not consistent across frames. For example, the nose point assinged to \"pup1\" in frame n and n+1 may belong to different individuals. The behavior classifiers consider the all the pups in the litter as a unit, so it is not necessary to know the idenities of individuals pups within or across frames. \n",
    "\n",
    "If you are interested tracking individual pups, you will need to convert detections to tracklets, stitch tracklets, and (optionally) refine tracklets using DeepLabCut. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38fe962",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pickle_dir = video_directory.replace(\"'\", \"\")\n",
    "PhenoPickleArgs = ['x', '-input_directory:' + pickle_dir]\n",
    "PhenoPickleRaw.main(PhenoPickleArgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59dffd7",
   "metadata": {},
   "source": [
    "# Join dam and pup pose estimation data\n",
    "\n",
    "Now that you have csv files for dam and pup tracking infomration for all of the videos, it can be combined and reformatted so it is ready for behavior classification in SimBA. to do this, run the join_dam_pup.py script. This script: \n",
    "1. Identifies CSV files for dam and pup videos based on the original video file name.\n",
    "2. Loads and preprocesses the data from these files.\n",
    "3. Merges the dam and pup data based on frame timestamps.\n",
    "4. Saves the merged data to CSV files in a subdirectory named 'AMBER_joined_pose_estimation'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea1d14a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main(argv):\n",
    "    print(\"Starting file joining...\")\n",
    "    all_files = os.listdir(video_directory)\n",
    "    \n",
    "    #given the video directory, find all files containing \"DLC_resnet50_dam-single-animalMay26shuffle\" and ending in \".csv\"\n",
    "    dam_files = []\n",
    "    dam_keys = []\n",
    "    for file in all_files:\n",
    "        if 'DLC_resnet50_dam-single-animalMay26shuffle' in file \\\n",
    "                and file.lower().endswith('.csv'):\n",
    "            dam_files.append(video_directory + os.sep + file)\n",
    "            dam_keys.append(file.split('DLC_resnet50_dam-single-animalMay26shuffle')[0])\n",
    "    #print(\"Dam files:\", dam_files)\n",
    "\n",
    "    #given the video directory, find all files containing \"DLC_dlcrnetms5_pup-nine-ptJun5shuffle\" and ending in \"UNPICKLED.csv\"\n",
    "    pup_files = []\n",
    "    pup_keys= []\n",
    "    for file in all_files:\n",
    "        if 'DLC_dlcrnetms5_pup-nine-ptJun5shuffle' in file \\\n",
    "                and file.lower().endswith('unpickled.csv'):\n",
    "            pup_files.append(video_directory + os.sep + file)\n",
    "            pup_keys.append(file.split('DLC_dlcrnetms5_pup-nine-ptJun5shuffle')[0])\n",
    "    #print(\"Pup files:\", pup_files)\n",
    "\n",
    "    #create paired_keys for files that have pup and dam pose estimation\n",
    "    dam_set = set(dam_keys)\n",
    "    pup_set = set(pup_keys)\n",
    "    paired_keys = list(dam_set.intersection(pup_set))\n",
    "    #print(\"Paired keys:\", paired_keys)\n",
    "\n",
    "    for key in paired_keys:\n",
    "        print('Joining', key)\n",
    "        for dam_file in dam_files:\n",
    "            if video_directory + os.sep + key + 'DLC_resnet50_dam-single-animalMay26shuffle' in dam_file:\n",
    "                dam_path = dam_file\n",
    "                break\n",
    "\n",
    "        dam_df = pd.read_csv(dam_path)\n",
    "        dam_df.columns = dam_df.iloc[0] + '_' + dam_df.iloc[1]\n",
    "        dam_df = dam_df.iloc[2:]\n",
    "        dam_df = dam_df.rename(columns= {'bodyparts_coords': 'frame'})\n",
    "        dam_df['frame'] =dam_df['frame'].astype(int)\n",
    "\n",
    "        for pup_file in pup_files:\n",
    "            if video_directory + os.sep + key + 'DLC_dlcrnetms5_pup-nine-ptJun5shuffle' in pup_file:\n",
    "                pup_path = pup_file\n",
    "                break\n",
    "\n",
    "        pup_df = pd.read_csv(pup_path)\n",
    "        print(\"pre merge\")\n",
    "        merged_df = dam_df.merge(pup_df, on='frame', how='left')\n",
    "        merged_df.loc[-2] = [column_name.replace('_x', '').replace('_y', '').replace('_likeihood','') for column_name in merged_df.columns]\n",
    "        merged_df.loc[-1] = ['coords'] + ['x', 'y', 'likelihood'] * int((len(merged_df.columns) - 1) / 3)\n",
    "        merged_df.index = merged_df.index + 2\n",
    "        merged_df.sort_index(inplace=True)\n",
    "        merged_df.columns = ['scorer'] + (['DLC_AMBER_dam_pup'] * (len(merged_df.columns) - 1))\n",
    "        merged_df.iloc[0, 0] = 'bodyparts'\n",
    "        print(\"post merge\")\n",
    "\n",
    "        try:\n",
    "            os.makedirs(video_directory + os.sep + 'AMBER_joined_pose_estimation' + os.sep)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        out_path = video_directory + os.sep + 'AMBER_joined_pose_estimation' + os.sep + key + '.csv'\n",
    "        merged_df.to_csv(out_path, index=False)\n",
    "        print(out_path)\n",
    "\n",
    "\n",
    "main(video_directory)\n",
    "\n",
    "print(\"Finished joining dam and pup files\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DEEPLABCUT] *",
   "language": "python",
   "name": "conda-env-DEEPLABCUT-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
